#!/usr/bin/env python3
import streamlit as st
from openai import OpenAI
from typing import Any
import base64
import io
from PIL import Image
from pypdf import PdfReader
import speech_recognition as sr
from gtts import gTTS
import tempfile
import os

# Configuration de la page
st.set_page_config(page_title="Cadre Diagnosticien", page_icon="üîß", layout="wide")

# R√©cup√©ration de la cl√© API et Configuration Client
def get_client():
    try:
        api_key = st.secrets["OPENROUTER_API_KEY"]
    except Exception:
        st.error("Cl√© API OpenRouter non trouv√©e dans .streamlit/secrets.toml")
        st.stop()
    
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=api_key,
    )
    return client

# System Prompt modifi√© pour le mode interactif
SYSTEM_PROMPT = """
R√¥le Principal : Tu es un Expert Diagnosticien Automobile Multimarque de niveau Master.
Tu pilotes un diagnostic interactif avec un m√©canicien sur le terrain.

Ton Objectif : Identifier la panne pr√©cise en proc√©dant √©tape par √©tape.

R√®gles d'Interaction (STRICTES) :
1. ANALYSE : Au d√©but, analyse les infos du v√©hicule, le sympt√¥me ET les √©ventuels documents/photos fournis.
2. √âTAPE PAR √âTAPE : Ne donne JAMAIS tout le diagnostic d'un coup. Propose UN SEUL test ou UNE SEULE v√©rification √† la fois.
3. LOGIQUE : Choisis le test le plus probable ou le plus rapide √† faire en premier.
4. INSTRUCTION PR√âCISE : Dis au m√©canicien quelle "Valeur R√©elle" lire au KTS ou quel "Test Actionneur" faire.
5. DOCUMENTATION : Si une documentation technique (PDF) est fournie, utilise ses valeurs de r√©f√©rence EN PRIORIT√â.
6. VISUEL : Si une photo est fournie (pi√®ce, √©cran KTS), analyse-la pour confirmer ou infirmer des hypoth√®ses.
7. ATTENTE : Finis ta r√©ponse en demandant le r√©sultat de ce test. Attends la r√©ponse du m√©canicien avant de continuer.
8. CONCLUSION : Uniquement quand tu es s√ªr √† 100% (apr√®s preuves), √©cris "PANNE IDENTIFI√âE :" suivi de la pi√®ce √† changer et d'une br√®ve explication.
9. VOCAL : Sois CONCIS. Tes r√©ponses seront lues √† haute voix. √âvite les listes √† puces trop longues.

Ton Style : Direct, Professionnel, Conci. Pas de bla-bla.

CRITIQUE : Si Hybride/√âlectrique -> Consignation s√©curit√© en priorit√© absolue.
"""

def process_image(uploaded_file) -> str:
    """Convertit l'image upload√©e en base64 pour l'API."""
    if uploaded_file is not None:
        bytes_data = uploaded_file.getvalue()
        base64_image = base64.b64encode(bytes_data).decode('utf-8')
        return f"data:image/jpeg;base64,{base64_image}"
    return ""

def process_pdf(uploaded_file) -> str:
    """Extrait le texte du PDF upload√©."""
    if uploaded_file is not None:
        try:
            reader = PdfReader(uploaded_file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            st.error(f"Erreur lecture PDF: {e}")
            return ""
    return ""

def safe_truncate(content: str | None, length: int) -> str:
    """Tronque une cha√Æne de caract√®res de mani√®re s√ªre."""
    if not content:
        return ""
    # Cast explicite pour le linter
    s = str(content)
    # Linter workaround: Slicing explicit
    if len(s) > length:
        return s[:length] # type: ignore
    return s

def transcribe_audio(audio_bytes):
    """Transcription audio via Google Speech Recognition."""
    r = sr.Recognizer()
    text = ""
    # Cr√©ation d'un fichier temporaire pour le traitement
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_audio:
        tmp_audio.write(audio_bytes)
        tmp_audio_path = tmp_audio.name

    try:
        with sr.AudioFile(tmp_audio_path) as source:
            # Enregistrement et nettoyage du bruit ambiant
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            # Reconnaissance (langue fran√ßaise)
            text = r.recognize_google(audio_data, language="fr-FR")
    except sr.UnknownValueError:
        pass # Audio non compris, on ignore silencieusement ou on log
    except sr.RequestError as e:
        st.error(f"Erreur Service Vocal : {e}")
    except Exception as e:
        st.error(f"Erreur Audio : {e}")
    finally:
        if os.path.exists(tmp_audio_path):
            os.remove(tmp_audio_path)
    return text

def text_to_speech(text):
    """Synth√®se vocale via gTTS."""
    try:
        tts = gTTS(text=text, lang='fr', slow=False)
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp_file:
            tts.save(tmp_file.name)
            return tmp_file.name
    except Exception as e:
        st.error(f"Erreur Synth√®se Vocale : {e}")
        return None

def get_ai_response(client, messages):
    # On utilise un mod√®le multimodal performant
    models = ["google/gemini-2.0-flash-001", "meta-llama/llama-3.3-70b-instruct:free"]
    
    for model in models:
        try:
            completion = client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "http://localhost:8501", 
                    "X-Title": "MecaDiag",
                },
                model=model,
                messages=messages,
            )
            return completion.choices[0].message.content
        except Exception as e:
            if model == models[-1]:
                raise e
            continue

def main():
    client = get_client()

    st.title("Diagnosticien Expert KTS (Multimodal & Vocal) üîß")

    # Initialisation de l'historique
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": SYSTEM_PROMPT}
        ]
    if "diagnostic_started" not in st.session_state:
        st.session_state.diagnostic_started = False
    
    # State pour l'audio processed pour √©viter les boucles
    if "last_audio_id" not in st.session_state:
        st.session_state.last_audio_id = None
    
    # State pour TTS autoplay
    if "last_tts_audio" not in st.session_state:
        st.session_state.last_tts_audio = None

    # --- Zone Info V√©hicule (sidebar enroulable) ---
    st.sidebar.markdown("### üöó V√©hicule")
    
    with st.sidebar.container():
        voiture_modele = st.text_input("Mod√®le", placeholder="Ex: Renault Clio 4", key="v_model")
        annee = st.number_input("Ann√©e", 1980, 2025, 2015, key="v_year")
        kilometrage = st.number_input("Km", 0, step=1000, value=100000, key="v_km")
        code_defaut = st.text_input("Code D√©faut / Sympt√¥me", placeholder="Ex: P0087", key="v_fault")
        carburant = st.selectbox("Carburant", ["Diesel", "Essence", "Hybride", "√âlectrique"], key="v_fuel")
        code_moteur = st.text_input("Code Moteur", placeholder="Ex: K9K", key="v_engine")
    
    st.sidebar.info("Remplissez les infos v√©hicule ici.")

    # --- Gestion de l'audio TTS (Autoplay) ---
    if st.session_state.last_tts_audio:
        st.audio(st.session_state.last_tts_audio, format="audio/mp3", autoplay=True)

    # --- Zone Journal du Diagnostic (Historique) ---
    st.subheader("üìù Journal du Diagnostic")
    
    # Container pour l'historique scrollable
    chat_container = st.container(height=600)
    with chat_container:
        for msg in st.session_state.messages:
            if msg["role"] != "system":
                with st.chat_message(msg["role"]):
                    if isinstance(msg["content"], list):
                        for content_part in msg["content"]:
                            if content_part["type"] == "text":
                                st.markdown(content_part["text"])
                            elif content_part["type"] == "image_url":
                                st.image(content_part["image_url"]["url"], width=200, caption="Image analys√©e")
                    else:
                        st.markdown(msg["content"])

    st.markdown("---")

    # --- Ergononomie Mobile : Espacement ---
    st.markdown("<br>", unsafe_allow_html=True)

    # --- Zone de Saisie & Outils (Commune) ---
    st.subheader("üîß Outils de Diagnostic")
    
    # Layout 3 colonnes pour les outils
    col_vision, col_doc, col_vocal = st.columns(3)
    
    # Outil 1 : Vision (Cam√©ra Directe)
    with col_vision:
        st.markdown("##### üì∑ Photo")
        # Remplacement par st.camera_input pour mobile
        uploaded_image = st.camera_input("Prendre photo", label_visibility="collapsed")
        if uploaded_image:
            st.success("‚úÖ Pr√™te")
        else:
            st.info("Ouvrir Cam√©ra")

    # Outil 2 : Doc
    with col_doc:
        st.markdown("##### üìÑ PDF")
        uploaded_pdf = st.file_uploader("PDF", type=["pdf"], label_visibility="collapsed")
        if uploaded_pdf:
            st.success("‚úÖ Pr√™t")
        else:
            st.info("Ajouter PDF")

    # Outil 3 : Vocal
    with col_vocal:
        st.markdown("##### üé§ Audio")
        audio_input = st.audio_input("Vocal", label_visibility="collapsed")
        
        # Logique de transcription imm√©diate
        processed_audio_text = None
        if audio_input is not None:
            current_audio_bytes = audio_input.getvalue()
            current_audio_id = hash(current_audio_bytes)
            st.success("‚úÖ Pr√™t")
    
    st.markdown("<br>", unsafe_allow_html=True)

    # --- Actions Contextuelles ---
    
    # Cas 1 : Le diagnostic n'a pas commenc√©
    if not st.session_state.diagnostic_started:
        
        st.markdown("##### üìù Observations & Lancement")
        symptomes_client = st.text_area(
            "Observations du client / Sympt√¥mes ressentis", 
            placeholder="Ex: Perte de puissance, bruit suspect...",
            height=100
        )
        
        st.markdown("<br>", unsafe_allow_html=True)

        # Bouton Lancer LARGE (Mobile)
        start_button = st.button("üöÄ LANCER LE DIAGNOSTIC", type="primary", use_container_width=True)

        if start_button:
            if not voiture_modele or not code_defaut:
                st.error("‚ö†Ô∏è Merci de remplir le Mod√®le et le Code D√©faut dans la barre lat√©rale.")
            else:
                # 1. Transcription Audio si pr√©sent
                audio_text = ""
                if audio_input:
                     with st.spinner("Transcription audio..."):
                        audio_text = transcribe_audio(audio_input.getvalue())
                
                # 2. Construction du Contexte
                contexte_km = "Attention: Fort kilom√©trage." if kilometrage > 200000 else ""
                
                pdf_text: str = process_pdf(uploaded_pdf)
                contexte_doc = ""
                if pdf_text and len(pdf_text) > 0:
                    truncated_text = safe_truncate(pdf_text, 30000)
                    contexte_doc = f"\n\n[CONTEXTE DOCUMENTAIRE PDF] :\n{truncated_text}..."
                
                # Fusion des observations
                obs_finales = symptomes_client
                if audio_text:
                    obs_finales += f" [VOCAL TRANSCRIT: {audio_text}]"

                initial_text = f"""
                NOUVEAU CAS :
                V√©hicule : {voiture_modele} ({annee}) - {carburant}
                Moteur : {code_moteur}
                Kilom√©trage : {kilometrage} km
                Probl√®me signal√© (Code/D√©faut) : {code_defaut}
                Sympt√¥mes ressentis / Observations : {obs_finales}
                {contexte_km}
                {contexte_doc}
                
                Analyse la situation et propose le premier test.
                """
                
                user_message_content: list[dict[str, Any]] = []
                user_message_content.append({"type": "text", "text": initial_text})
                
                image_url = process_image(uploaded_image)
                if image_url:
                    user_message_content.append({
                        "type": "image_url",
                        "image_url": {"url": image_url}
                    })

                st.session_state.messages.append({"role": "user", "content": user_message_content}) # type: ignore
                st.session_state.diagnostic_started = True
                
                with st.spinner("üß† Analyse Expert en cours..."):
                    response = get_ai_response(client, st.session_state.messages)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    audio_file = text_to_speech(response)
                    if audio_file:
                        st.session_state.last_tts_audio = audio_file
                        
                    st.rerun()

    # Cas 2 : Diagnostic en cours
    else:
        st.markdown("##### üí¨ R√©ponse au Test")
        
        observation = st.text_input("R√©sultat du test / Observation", key="user_input_running")
        
        st.markdown("<br>", unsafe_allow_html=True)

        col_send, col_new = st.columns([3, 1])
        with col_send:
            # Bouton Envoyer LARGE (Mobile)
            send_clicked = st.button("üì® ENVOYER LA R√âPONSE", type="primary", use_container_width=True)
        with col_new:
            # Bouton Nouveau LARGE
            new_diag = st.button("üîÑ Nouveau", use_container_width=True)
        
        if new_diag:
            st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]
            st.session_state.diagnostic_started = False
            st.session_state.last_audio_id = None
            st.session_state.last_tts_audio = None
            st.rerun()

        if send_clicked:
            # 1. Transcription Audio si pr√©sent
            audio_text = ""
            if audio_input:
                with st.spinner("Transcription audio..."):
                    audio_text = transcribe_audio(audio_input.getvalue())

            # Priorit√© : Audio > Texte saisi > Rien
            input_text = observation
            if audio_text:
                input_text += f" [VOCAL TRANSCRIT: {audio_text}]"
            
            # On envoie seulement s'il y a du contenu
            if input_text or uploaded_image or uploaded_pdf:
                user_message_content: list[dict[str, Any]] = []
                
                text_content = input_text if input_text else "Voici un compl√©ment d'information."
                
                pdf_text: str = process_pdf(uploaded_pdf)
                if pdf_text and len(pdf_text) > 0:
                    truncated_text = safe_truncate(pdf_text, 20000)
                    text_content += f"\n\n[NOUVELLE DOC PDF FOURNIE] :\n{truncated_text}..."
                
                user_message_content.append({"type": "text", "text": text_content})
                
                image_url = process_image(uploaded_image)
                if image_url:
                    user_message_content.append({
                        "type": "image_url",
                        "image_url": {"url": image_url}
                    })
                
                st.session_state.messages.append({"role": "user", "content": user_message_content}) # type: ignore
                
                with st.spinner("üß† Analyse des nouvelles donn√©es..."):
                    response = get_ai_response(client, st.session_state.messages)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    audio_file = text_to_speech(response)
                    if audio_file:
                        st.session_state.last_tts_audio = audio_file
                        
                    st.rerun()
            else:
                st.warning("‚ö†Ô∏è Veuillez saisir une r√©ponse, parler, ou ajouter une photo/doc.")

if __name__ == "__main__":
    main()